{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import spikeinterface.full as si\n",
    "from probeinterface.plotting import plot_probe, plot_probegroup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import gridspec\n",
    "from scipy import stats\n",
    "import os\n",
    "from Helpers import plot_utility\n",
    "from astropy.nddata import block_reduce\n",
    "import matplotlib.ticker as ticker\n",
    "from Helpers.plot_utility import pandas_collumn_to_2d_numpy_array, pandas_collumn_to_numpy_array\n",
    "from P3_CurrentAnalysis.basic_lomb_scargle_estimator import lomb_scargle_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_firing_rate_maps_per_trial_2(cluster_spike_data, track_length, save_path=None, ax=None):\n",
    "    firing_times_cluster = cluster_spike_data[\"firing_times_vr\"].iloc[0]\n",
    "    if len(firing_times_cluster)>1:\n",
    "        cluster_firing_maps = np.array(cluster_spike_data['fr_binned_in_space_smoothed'].iloc[0])\n",
    "        cluster_firing_maps[np.isnan(cluster_firing_maps)] = 0\n",
    "        cluster_firing_maps[np.isinf(cluster_firing_maps)] = 0\n",
    "        percentile_99th_display = np.nanpercentile(cluster_firing_maps, 95)\n",
    "        cluster_firing_maps = min_max_normalize(cluster_firing_maps)\n",
    "        percentile_99th = np.nanpercentile(cluster_firing_maps, 95)\n",
    "        cluster_firing_maps = np.clip(cluster_firing_maps, a_min=0, a_max=percentile_99th)\n",
    "        vmin, vmax = get_vmin_vmax(cluster_firing_maps)\n",
    "\n",
    "        locations = np.arange(0, len(cluster_firing_maps[0]))\n",
    "        ordered = np.arange(0, len(cluster_firing_maps), 1)\n",
    "        X, Y = np.meshgrid(locations, ordered)\n",
    "        if ax is None:\n",
    "            fig = plt.figure()\n",
    "            fig.set_size_inches(5, 5, forward=True)\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        ax.pcolormesh(X, Y, cluster_firing_maps, shading=\"auto\", vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(str(np.round(percentile_99th_display, decimals=1))+\" Hz\", fontsize=20)\n",
    "        ax.set_ylabel('Trial Number', fontsize=20, labelpad = 20)\n",
    "        ax.set_xlabel('Location (cm)', fontsize=20, labelpad = 20)\n",
    "        ax.set_xlim([0, track_length])\n",
    "        ax.set_ylim([0, len(cluster_firing_maps)-1])\n",
    "        ax.tick_params(axis='both', which='both', labelsize=20)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        tick_spacing = 100\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(tick_spacing))\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        #cbar = spikes_on_track.colorbar(c, ax=ax, fraction=0.046, pad=0.04)\n",
    "        #cbar.set_label('Firing Rate (Hz)', rotation=270, fontsize=20)\n",
    "        #cbar.set_ticks([0,np.max(cluster_firing_maps)])\n",
    "        #cbar.set_ticklabels([\"0\", \"Max\"])\n",
    "        #cbar.ax.tick_params(labelsize=20)\n",
    "        plt.subplots_adjust(hspace = .35, wspace = .35,  bottom = 0.2, left = 0.3, right = 0.87, top = 0.92)\n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path + '/firing_rate_map_trials_' + \n",
    "                        spike_data.session_id.iloc[cluster_index] + '_' + \n",
    "                        str(int(cluster_id)) + '.png', dpi=300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_firing_rate_maps_short(cluster_data, track_length=200, ax=None, save_path=None):\n",
    "    firing_times_cluster = cluster_data[\"firing_times_vr\"].iloc[0]\n",
    "    cluster_id = cluster_data[\"cluster_id\"].iloc[0]\n",
    "\n",
    "    if len(firing_times_cluster)>1:\n",
    "        cluster_firing_maps = np.array(cluster_data['fr_binned_in_space_smoothed'].iloc[0])\n",
    "        cluster_firing_maps[np.isnan(cluster_firing_maps)] = np.nan\n",
    "        cluster_firing_maps[np.isinf(cluster_firing_maps)] = np.nan\n",
    "\n",
    "        if ax is None: \n",
    "            spikes_on_track = plt.figure()\n",
    "            spikes_on_track.set_size_inches(5, 5/3, forward=True)\n",
    "            ax = spikes_on_track.add_subplot(1, 1, 1)\n",
    "        \n",
    "        locations = np.arange(0, len(cluster_firing_maps[0]))\n",
    "        ax.fill_between(locations, np.nanmean(cluster_firing_maps, axis=0) - stats.sem(cluster_firing_maps, axis=0,nan_policy=\"omit\"),\n",
    "                                    np.nanmean(cluster_firing_maps, axis=0) + stats.sem(cluster_firing_maps, axis=0,nan_policy=\"omit\"), color=\"black\", alpha=0.2)\n",
    "        ax.plot(locations, np.nanmean(cluster_firing_maps, axis=0), color=\"black\", linewidth=1)\n",
    "        \n",
    "        #plt.ylabel('FR (Hz)', fontsize=25, labelpad = 10)\n",
    "        #plt.xlabel('Location (cm)', fontsize=25, labelpad = 10)\n",
    "        plt.xlim(0, track_length)\n",
    "        ax.tick_params(axis='both', which='both', labelsize=20)\n",
    "        ax.set_xlim([0, track_length])\n",
    "        max_fr = max(np.nanmean(cluster_firing_maps, axis=0)+stats.sem(cluster_firing_maps, axis=0))\n",
    "        max_fr = max_fr+(0.1*(max_fr))\n",
    "        #ax.set_ylim([0, max_fr])\n",
    "        ax.set_yticks([0, np.round(ax.get_ylim()[1], 1)])\n",
    "        ax.set_ylim(bottom=0)\n",
    "        plot_utility.style_track_plot(ax, track_length, alpha=0.15)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(100))\n",
    "        ax.yaxis.set_ticks_position('left')\n",
    "        ax.xaxis.set_ticks_position('bottom')\n",
    "        plt.subplots_adjust(hspace = .35, wspace = .35,  bottom = 0.2, left = 0.3, right = 0.87, top = 0.92)\n",
    "        if save_path is not None:\n",
    "            plt.savefig(save_path + '/avg_firing_rate_maps_short_' + cluster_data.session_id.iloc[0] + '_' + str(int(cluster_id)) + '.png', dpi=300)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(x):\n",
    "    \"\"\"\n",
    "        argument\n",
    "            - x: input image data in numpy array [32, 32, 3]\n",
    "        return\n",
    "            - normalized x\n",
    "    \"\"\"\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (max_val-min_val)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vmin_vmax(cluster_firing_maps, bin_cm=8):\n",
    "    cluster_firing_maps_reduced = []\n",
    "    for i in range(len(cluster_firing_maps)):\n",
    "        cluster_firing_maps_reduced.append(block_reduce(cluster_firing_maps[i], bin_cm, func=np.mean))\n",
    "    cluster_firing_maps_reduced = np.array(cluster_firing_maps_reduced)\n",
    "    vmin= 0\n",
    "    vmax= np.max(cluster_firing_maps_reduced)\n",
    "    return vmin, vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramp_score(ramp_data_vr):\n",
    "    ramp_data_vr = ramp_data_vr.fillna('None') # replace None types with None strings for ease\n",
    "    df = pd.DataFrame()\n",
    "    for cluster_id in np.unique(ramp_data_vr[\"cluster_id\"]):\n",
    "\n",
    "        outbound = ramp_data_vr[(ramp_data_vr[\"cluster_id\"] == cluster_id) &\n",
    "                                (ramp_data_vr[\"trial_type\"] == \"None\") &\n",
    "                                (ramp_data_vr[\"hit_miss_try\"] == \"None\") &\n",
    "                                (ramp_data_vr[\"track_length\"] == \"outbound\")][\"ramp_class\"].iloc[0]\n",
    "        homebound = ramp_data_vr[(ramp_data_vr[\"cluster_id\"] == cluster_id) &\n",
    "                                 (ramp_data_vr[\"trial_type\"] == \"None\") &\n",
    "                                 (ramp_data_vr[\"hit_miss_try\"] == \"None\") &\n",
    "                                 (ramp_data_vr[\"track_length\"] == \"homebound\")][\"ramp_class\"].iloc[0]\n",
    "        ramp_class = outbound+homebound\n",
    "        cluster_df = pd.DataFrame({'cluster_id': [cluster_id],\n",
    "                                   'outbound_homebound_ramp_class': [ramp_class]})\n",
    "        df = pd.concat([df, cluster_df], ignore_index=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spatial_information(spatial_firing, position_data, track_length):\n",
    "    position_heatmap = np.zeros(track_length)\n",
    "    for x in np.arange(track_length):\n",
    "        bin_occupancy = len(position_data[(position_data[\"x_position_cm\"] > x) &\n",
    "                                                (position_data[\"x_position_cm\"] <= x+1)])\n",
    "        position_heatmap[x] = bin_occupancy\n",
    "    position_heatmap = position_heatmap*np.diff(position_data[\"time_seconds\"])[-1] # convert to real time in seconds\n",
    "    occupancy_probability_map = position_heatmap/np.sum(position_heatmap) # Pj\n",
    "\n",
    "    spatial_information_scores_Ispike = []\n",
    "    spatial_information_scores_Isec = []\n",
    "    for cluster_index, cluster_id in enumerate(spatial_firing.cluster_id):\n",
    "        cluster_df = spatial_firing[(spatial_firing.cluster_id == cluster_id)] # dataframe for that cluster\n",
    "\n",
    "        mean_firing_rate = len(cluster_df.iloc[0][\"firing_times\"])/np.sum(len(position_data)*np.diff(position_data[\"time_seconds\"])[-1]) # λ\n",
    "        spikes, _ = np.histogram(np.array(cluster_df['x_position_cm'].iloc[0]), bins=track_length, range=(0,track_length))\n",
    "        rates = spikes/position_heatmap\n",
    "\n",
    "        Isec, Ispike = spatial_info(mean_firing_rate, occupancy_probability_map, rates)\n",
    "\n",
    "        spatial_information_scores_Ispike.append(Ispike)\n",
    "        spatial_information_scores_Isec.append(Isec)\n",
    "\n",
    "    spatial_firing[\"spatial_information_score_Isec\"] = spatial_information_scores_Isec\n",
    "    spatial_firing[\"spatial_information_score_Ispike\"] = spatial_information_scores_Ispike\n",
    "    return spatial_firing\n",
    "\n",
    "def spatial_info(mrate, occupancy_probability_map, rates):\n",
    "    Isec = np.sum(occupancy_probability_map * rates * np.log2((rates / mrate) + 0.0001))\n",
    "    Ispike = Isec / mrate\n",
    "    return Isec, Ispike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_network_anchor(spike_data, position_data):\n",
    "    filtered_df = pd.DataFrame()\n",
    "    for i, cluster_df in spike_data.iterrows():\n",
    "        cluster_df = cluster_df.to_frame().T.reset_index(drop=True)\n",
    "        if isinstance(cluster_df['ls_deltas'].iloc[0], np.ndarray):\n",
    "            filtered_df = pd.concat([filtered_df, cluster_df], ignore_index=True)\n",
    "\n",
    "    filtered_df = calculate_spatial_information(filtered_df, position_data, track_length=200)\n",
    "    filtered_df = filtered_df.sort_values(by=[\"shank_id_x\", \"spatial_information_score_Isec\"], ascending=False)\n",
    "\n",
    "    data = pandas_collumn_to_2d_numpy_array(filtered_df[\"ls_deltas\"])\n",
    "    print(np.shape(data))\n",
    "    \n",
    "    plt.imshow(data, cmap='viridis', aspect='auto')\n",
    "    plt.colorbar(label='ls delta')\n",
    "    plt.show()\n",
    "    plt.plot(np.arange(len(data[0])), np.nanmean(data, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M21 ramp cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"/mnt/datastore/Harry/Cohort11_april2024/derivatives/\"\n",
    "# get sorting analyzer and unit locations\n",
    "of_session_base_names = [\"M21_D26_2024-05-28_16-35-31_OF1\", \"M21_D23_2024-05-25_16-07-17_OF1\", \"M21_D25_2024-05-27_15-35-57_OF1\", \"M21_D24_2024-05-26_15-58-23_OF1\"]\n",
    "vr_session_base_names = [\"M21_D26_2024-05-28_17-04-41_VR1\", \"M21_D23_2024-05-25_16-54-12_VR1\", \"M21_D25_2024-05-27_16-00-30_VR1\", \"M21_D24_2024-05-26_16-35-19_VR1\"]\n",
    " \n",
    "M21_master_data = pd.DataFrame()\n",
    "for vr_name, of_name in zip(vr_session_base_names, of_session_base_names):\n",
    "    mouse = vr_name.split(\"_\")[0]\n",
    "    day = vr_name.split(\"_\")[1]\n",
    "    sorting_analyzer_path = f\"{project_path}{mouse}/{day}/ephys/sorting_analyzer\"\n",
    "    vr_path = f\"{project_path}{mouse}/{day}/vr/{vr_name}/processed/kilosort4/spikes.pkl\"\n",
    "    ramp_path = f\"{project_path}{mouse}/{day}/vr/{vr_name}/processed/kilosort4/ramp_classifications.pkl\"\n",
    "    of_path = f\"{project_path}{mouse}/{day}/of/{of_name}/processed/kilosort4/spikes.pkl\"\n",
    "\n",
    "    spike_data_vr = pd.read_pickle(vr_path); spike_data_vr[\"firing_times_vr\"] = spike_data_vr[\"firing_times\"]; spike_data_vr[\"session_id_vr\"] = vr_name\n",
    "    spike_data_of = pd.read_pickle(of_path); spike_data_of[\"firing_times_of\"] = spike_data_of[\"firing_times\"]; spike_data_of[\"session_id_of\"] = of_name\n",
    "    ramp_data_vr = pd.read_pickle(ramp_path)\n",
    "    ramp_data_vr = ramp_score(ramp_data_vr)\n",
    "    spike_data = pd.merge(spike_data_vr, spike_data_of, on=\"cluster_id\")\n",
    "    spike_data = pd.merge(spike_data, ramp_data_vr, on=\"cluster_id\")\n",
    "    M21_master_data = pd.concat([M21_master_data, spike_data])\n",
    "\n",
    "### curate\n",
    "print(f\"pre-curation M21: {len(M21_master_data)}\")\n",
    "M21_master_data = M21_master_data[(M21_master_data[\"snr_x\"] > 1) & (M21_master_data[\"mean_firing_rate_x\"] > 0.5) & (M21_master_data[\"rp_contamination_x\"] < 0.9)]\n",
    "print(f\"post-curation M21: {len(M21_master_data)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = M21_master_data[M21_master_data['grid_score'] > 0.7]\n",
    "for i, cluster_df in subset.iterrows():\n",
    "    cluster_df = cluster_df.to_frame().T.reset_index(drop=True)\n",
    "    cluster_id = cluster_df[\"cluster_id\"].iloc[0]\n",
    "    grid_score = cluster_df[\"grid_score\"].iloc[0]\n",
    "    session_id_vr = cluster_df[\"session_id_vr\"].iloc[0]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4, 4)) \n",
    "    plot_firing_rate_maps_per_trial_2(cluster_df, track_length=200, ax=ax, save_path=None)\n",
    "    plt.savefig(f\"/mnt/datastore/Harry/plot_viewer/grid_maps/c{cluster_id}_long_{session_id_vr}.png\", dpi=100)\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(figsize=(4, 2)) \n",
    "    plot_firing_rate_maps_short(cluster_df, track_length=200, ax=ax, save_path=None)\n",
    "    ax.set_title(f\"GS: {np.round(grid_score, decimals=2)}\")\n",
    "    plt.savefig(f\"/mnt/datastore/Harry/plot_viewer/grid_maps/c{cluster_id}_short_{session_id_vr}.png\", dpi=100)\n",
    "    plt.close()\n",
    "    plt.close('all')\n",
    "\n",
    "print()\n",
    " \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"/mnt/datastore/Harry/Cohort11_april2024/derivatives/\"\n",
    "# get sorting analyzer and unit locations\n",
    "of_session_base_names = [\"M21_D26_2024-05-28_16-35-31_OF1\"]\n",
    "vr_session_base_names = [\"M21_D26_2024-05-28_17-04-41_VR1\"]\n",
    " \n",
    "M21_D26_master_data = pd.DataFrame()\n",
    "for vr_name, of_name in zip(vr_session_base_names, of_session_base_names):\n",
    "    mouse = vr_name.split(\"_\")[0]\n",
    "    day = vr_name.split(\"_\")[1]\n",
    "    sorting_analyzer_path = f\"{project_path}{mouse}/{day}/ephys/sorting_analyzer\"\n",
    "    vr_path = f\"{project_path}{mouse}/{day}/vr/{vr_name}/processed/kilosort4/spikes.pkl\"\n",
    "    ramp_path = f\"{project_path}{mouse}/{day}/vr/{vr_name}/processed/kilosort4/ramp_classifications.pkl\"\n",
    "    of_path = f\"{project_path}{mouse}/{day}/of/{of_name}/processed/kilosort4/spikes.pkl\"\n",
    "\n",
    "    spike_data_vr = pd.read_pickle(vr_path); spike_data_vr[\"firing_times_vr\"] = spike_data_vr[\"firing_times\"]; spike_data_vr[\"session_id_vr\"] = vr_name\n",
    "    spike_data_of = pd.read_pickle(of_path); spike_data_of[\"firing_times_of\"] = spike_data_of[\"firing_times\"]; spike_data_of[\"session_id_of\"] = of_name\n",
    "    ramp_data_vr = pd.read_pickle(ramp_path)\n",
    "    ramp_data_vr = ramp_score(ramp_data_vr)\n",
    "    spike_data = pd.merge(spike_data_vr, spike_data_of, on=\"cluster_id\")\n",
    "    spike_data = pd.merge(spike_data, ramp_data_vr, on=\"cluster_id\")\n",
    "    M21_D26_master_data = pd.concat([M21_D26_master_data, spike_data])\n",
    "\n",
    "### curate\n",
    "print(f\"pre-curation M21: {len(M21_D26_master_data)}\")\n",
    "M21_D26_master_data = M21_D26_master_data[(M21_D26_master_data[\"snr_x\"] > 1) & (M21_D26_master_data[\"mean_firing_rate_x\"] > 0.5) & (M21_D26_master_data[\"rp_contamination_x\"] < 0.9)]\n",
    "print(f\"post-curation M21: {len(M21_D26_master_data)}\")\n",
    "position_path = f\"{project_path}{mouse}/{day}/vr/{vr_name}/processed/position_data.pkl\"\n",
    "position_data = pd.read_pickle(position_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'firing_times'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/si/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'firing_times'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mls_deltas\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(spike_data):\n\u001b[1;32m     27\u001b[0m     spike_data \u001b[38;5;241m=\u001b[39m lomb_scargle_parallel(spike_data, processed_position_data, track_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mplot_network_anchor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspike_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspike_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m, in \u001b[0;36mplot_network_anchor\u001b[0;34m(spike_data, position_data)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cluster_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mls_deltas\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m      6\u001b[0m         filtered_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([filtered_df, cluster_df], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_spatial_information\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m filtered_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshank_id_x\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspatial_information_score_Isec\u001b[39m\u001b[38;5;124m\"\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     11\u001b[0m data \u001b[38;5;241m=\u001b[39m pandas_collumn_to_2d_numpy_array(filtered_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mls_deltas\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m, in \u001b[0;36mcalculate_spatial_information\u001b[0;34m(spatial_firing, position_data, track_length)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cluster_index, cluster_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(spatial_firing\u001b[38;5;241m.\u001b[39mcluster_id):\n\u001b[1;32m     13\u001b[0m     cluster_df \u001b[38;5;241m=\u001b[39m spatial_firing[(spatial_firing\u001b[38;5;241m.\u001b[39mcluster_id \u001b[38;5;241m==\u001b[39m cluster_id)] \u001b[38;5;66;03m# dataframe for that cluster\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     mean_firing_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mcluster_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfiring_times\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mlen\u001b[39m(position_data)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mdiff(position_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m# λ\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     spikes, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram(np\u001b[38;5;241m.\u001b[39marray(cluster_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_position_cm\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]), bins\u001b[38;5;241m=\u001b[39mtrack_length, \u001b[38;5;28mrange\u001b[39m\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,track_length))\n\u001b[1;32m     17\u001b[0m     rates \u001b[38;5;241m=\u001b[39m spikes\u001b[38;5;241m/\u001b[39mposition_heatmap\n",
      "File \u001b[0;32m~/miniconda3/envs/si/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/miniconda3/envs/si/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/si/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'firing_times'"
     ]
    }
   ],
   "source": [
    "project_path = \"/mnt/datastore/Harry/Cohort11_april2024/derivatives/\"\n",
    "# get sorting analyzer and unit locations\n",
    "of_session_base_names = [\"M21_D26_2024-05-28_16-35-31_OF1\", \"M21_D23_2024-05-25_16-07-17_OF1\", \"M21_D25_2024-05-27_15-35-57_OF1\", \"M21_D24_2024-05-26_15-58-23_OF1\"]\n",
    "vr_session_base_names = [\"M21_D26_2024-05-28_17-04-41_VR1\", \"M21_D23_2024-05-25_16-54-12_VR1\", \"M21_D25_2024-05-27_16-00-30_VR1\", \"M21_D24_2024-05-26_16-35-19_VR1\"]\n",
    " \n",
    "\n",
    "for vr_name, of_name in zip(vr_session_base_names, of_session_base_names):\n",
    "    mouse = vr_name.split(\"_\")[0]\n",
    "    day = vr_name.split(\"_\")[1]\n",
    "    sorting_analyzer_path = f\"{project_path}{mouse}/{day}/ephys/sorting_analyzer\"\n",
    "    vr_path = f\"{project_path}{mouse}/{day}/vr/{vr_name}/processed/kilosort4/spikes.pkl\"\n",
    "    ramp_path = f\"{project_path}{mouse}/{day}/vr/{vr_name}/processed/kilosort4/ramp_classifications.pkl\"\n",
    "    of_path = f\"{project_path}{mouse}/{day}/of/{of_name}/processed/kilosort4/spikes.pkl\"\n",
    "    position_path = f\"{project_path}{mouse}/{day}/vr/{vr_name}/processed/position_data.csv\"\n",
    "    processed_position_path = f\"{project_path}{mouse}/{day}/vr/{vr_name}/processed/processed_position_data.pkl\"\n",
    "    position_data = pd.read_csv(position_path)\n",
    "    processed_position_data = pd.read_pickle(processed_position_path)\n",
    "    spike_data_vr = pd.read_pickle(vr_path); spike_data_vr[\"firing_times_vr\"] = spike_data_vr[\"firing_times\"]; spike_data_vr[\"session_id_vr\"] = vr_name\n",
    "    spike_data_of = pd.read_pickle(of_path); spike_data_of[\"firing_times_of\"] = spike_data_of[\"firing_times\"]; spike_data_of[\"session_id_of\"] = of_name\n",
    "    ramp_data_vr = pd.read_pickle(ramp_path)\n",
    "    ramp_data_vr = ramp_score(ramp_data_vr)\n",
    "    spike_data = pd.merge(spike_data_vr, spike_data_of, on=\"cluster_id\")\n",
    "    spike_data = pd.merge(spike_data, ramp_data_vr, on=\"cluster_id\")\n",
    "    spike_data[\"firing_times\"] = spike_data[\"firing_times_vr\"]\n",
    "    spike_data = spike_data[(spike_data[\"snr_x\"] > 1) & (spike_data[\"mean_firing_rate_x\"] > 0.5) & (spike_data[\"rp_contamination_x\"] < 0.9)]\n",
    "\n",
    "    if \"ls_deltas\" not in list(spike_data):\n",
    "        spike_data = lomb_scargle_parallel(spike_data, processed_position_data, track_length=200)\n",
    "        \n",
    "    plot_network_anchor(spike_data=spike_data, position_data=position_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pandas_collumn_to_2d_numpy_array(filtered_df[\"ls_deltas\"])\n",
    "print(np.shape(data))\n",
    "# Create the heatmap\n",
    "plt.imshow(data, cmap='viridis', aspect='auto')\n",
    "plt.colorbar(label='Value')\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Heatmap of Values Between 0 and 0.5')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "\n",
    "# Display the heatmap\n",
    "plt.show()\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
